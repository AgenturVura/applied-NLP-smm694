{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "\n",
    "# ― NER in action with Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Flair?\n",
    "\n",
    "There are several arguments:\n",
    "\n",
    "+ It builds upon PyTorch, which excels on many dimensions\n",
    "+ It's flexible ― users can choose among several models\n",
    "+ It draws upon novel, context-aware models (BERT & friends)  \n",
    "+ It has its own embeddings\n",
    "+ In relative terms, it's very accurate\n",
    "\n",
    "<img src='images/_22.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair's competitors\n",
    "\n",
    "<img src='images/_21.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy's prodigy library\n",
    "\n",
    "<img src='images/_23.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of Flair\n",
    "\n",
    "Flair depends on a fair number of complex libraries; here are some tips to\n",
    "to succesfully go through the installation process:\n",
    "\n",
    "+ create an ad-hoc environment\n",
    "+ Python 3.6/3.7 are preferrable\n",
    "+ Install PyTorch (torch) first\n",
    "+ `pip install flair` (even if you're Conda user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Flair + some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair.datasets\n",
    "from flair.models import SequenceTagger\n",
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.embeddings import FlairEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-24 11:20:10,077 loading file /home/simone/.flair/models/en-ner-conll03-v0.4.pt\n",
      "2020-06-24 11:20:12,484 loading file /home/simone/.flair/models/en-frame-ontonotes-v0.4.pt\n",
      "2020-06-24 11:20:13,929 Reading data from /home/simone/.flair/datasets/ud_english\n",
      "2020-06-24 11:20:13,929 Train: /home/simone/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2020-06-24 11:20:13,930 Dev: /home/simone/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2020-06-24 11:20:13,930 Test: /home/simone/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('ner')\n",
    "framing = SequenceTagger.load('frame')\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "corpus = flair.datasets.UD_ENGLISH()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences are the fundamental unit of analysis in Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sentence (by S. Johnson)\n",
    "document = 'when a man is tired of London, he is tired of life'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a Flair sentence\n",
    "sentence = Sentence(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"when a man is tired of London, he is tired of life\"   [− Tokens: 12  − Token-Labels: \"when a man is tired of London, <S-LOC> he is tired of life\"]\n"
     ]
    }
   ],
   "source": [
    "# print sentence\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-24 11:03:46,633 loading file /home/simone/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"George Washington went to Washington .\"   [− Tokens: 6  − Token-Labels: \"George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\"]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...OR run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize your sentence\n",
    "sentence = Sentence(document, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 when\n",
      "Token: 2 a\n",
      "Token: 3 man\n",
      "Token: 4 is\n",
      "Token: 5 tired\n",
      "Token: 6 of\n",
      "Token: 7 London\n",
      "Token: 8 ,\n",
      "Token: 9 he\n",
      "Token: 10 is\n",
      "Token: 11 tired\n",
      "Token: 12 of\n",
      "Token: 13 life\n"
     ]
    }
   ],
   "source": [
    "# inspect tokens\n",
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "+ the segtock library is the default tokenizer of Flair\n",
    "+ custom tokenizers can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Token: 2 wine\" is tagged as \"color\" with confidence score \"1.0\"\n"
     ]
    }
   ],
   "source": [
    "# sample sentence\n",
    "sentence = Sentence('Red wine is my favourite')\n",
    "\n",
    "# get token 1 in the sentence \n",
    "token = sentence[1]\n",
    "\n",
    "# add label\n",
    "token.add_tag('ner', 'color')\n",
    "\n",
    "# get the 'ner' tag of the token\n",
    "tag = token.get_tag('ner')\n",
    "\n",
    "# print token\n",
    "print(f'\"{token}\" is tagged as \"{tag.value}\" with confidence score \"{tag.score}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"France is the current world cup winner.\"   [− Tokens: 7  − Sentence-Labels: {'topic': [sports (1.0), soccer (1.0)], 'language': [English (1.0)]}]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('France is the current world cup winner.')\n",
    "\n",
    "# this sentence has multiple \"topic\" labels\n",
    "sentence.add_label('topic', 'sports')\n",
    "sentence.add_label('topic', 'soccer')\n",
    "\n",
    "# this sentence has a \"language\" labels\n",
    "sentence.add_label('language', 'English')\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports (1.0)\n",
      "soccer (1.0)\n",
      "English (1.0)\n"
     ]
    }
   ],
   "source": [
    "for label in sentence.labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging with pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington .')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [1,2]: \"George Washington\"   [− Labels: PER (0.9968)]\n",
      "Span [5]: \"Washington\"   [− Labels: LOC (0.9994)]\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': [{'end_pos': 17,\n",
      "               'labels': [PER (0.9968)],\n",
      "               'start_pos': 0,\n",
      "               'text': 'George Washington'},\n",
      "              {'end_pos': 36,\n",
      "               'labels': [LOC (0.9994)],\n",
      "               'start_pos': 26,\n",
      "               'text': 'Washington'}],\n",
      " 'labels': [],\n",
      " 'text': 'George Washington went to Washington .'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-24 11:03:01,406 loading file /home/simone/.flair/models/en-frame-ontonotes-v0.4.pt\n",
      "('George <_> returned <return.01> to <_> Berlin <_> to <_> return <return.02> '\n",
      " 'his <_> hat <_> . <_>')\n",
      "'He <_> had <have.03> a <_> look <look.01> at <_> different <_> hats <_> . <_>'\n"
     ]
    }
   ],
   "source": [
    "# make English sentence\n",
    "sentence_1 = Sentence('George returned to Berlin to return his hat .')\n",
    "sentence_2 = Sentence('He had a look at different hats .')\n",
    "\n",
    "# predict NER tags\n",
    "framing.predict(sentence_1)\n",
    "framing.predict(sentence_2)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "pprint(sentence_1.to_tagged_string())\n",
    "pprint(sentence_2.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 Red\n",
      "tensor([-0.3002,  0.5015, -0.1275, -0.8164,  0.3361,  0.3221, -0.0474,  0.0371,\n",
      "        -0.6158, -0.2233, -0.3913, -0.3189,  0.8709,  0.7445,  0.2371,  0.3177,\n",
      "         0.6132, -0.4816,  0.5545, -0.4877, -0.1187,  0.1520, -0.4388,  0.0452,\n",
      "         0.6666,  0.6442, -0.2181, -0.2422,  0.1765, -0.7179,  0.4889,  0.2287,\n",
      "         0.0800,  0.1224,  0.1864,  0.2052, -0.3514,  0.8317,  0.8658,  0.3340,\n",
      "         0.4451, -0.9813, -0.1045, -0.1020,  0.6549,  0.1068, -0.0953,  0.5637,\n",
      "         0.0488, -0.1084,  0.1054,  0.0412, -0.2939,  1.0227, -0.8657, -2.5878,\n",
      "        -0.5008,  0.9758,  1.5560,  0.4521, -0.5428,  0.8199, -0.6083,  0.1992,\n",
      "         0.7497, -0.3914,  0.0605, -0.0569, -0.0121,  0.0621,  0.0706, -0.4798,\n",
      "        -0.8661, -0.5934,  0.5765,  0.9837, -0.0351,  0.4203, -0.4059,  0.3510,\n",
      "         0.8739, -0.0694, -0.6869,  0.1860, -0.3690, -0.0218, -0.1014, -0.0376,\n",
      "         0.5682,  0.7438, -0.2871, -1.0705, -0.5070, -0.1258, -0.9040, -0.2559,\n",
      "        -1.3706,  0.1731,  0.1293, -0.4852])\n",
      "Token: 2 wine\n",
      "tensor([-0.4765,  0.4209,  0.1742, -0.0558,  0.2044,  0.3640,  1.0813,  0.3260,\n",
      "         0.0963, -0.4436, -0.7446, -0.6448, -0.2799,  0.2217, -1.0897,  0.2020,\n",
      "         0.8254, -0.5224, -0.7204,  0.8119, -0.6910,  0.1812, -0.3226, -0.8353,\n",
      "        -0.1770,  0.5722, -0.3487, -0.7293, -0.4237, -1.0600, -0.1819, -0.0844,\n",
      "         0.0627, -1.3184,  0.5756,  1.1970,  0.3082,  0.1086,  0.2251, -0.6283,\n",
      "         0.0917, -0.8229, -0.0500, -0.8649,  1.0282, -0.1852, -0.6962, -0.8606,\n",
      "         0.2283, -0.9593,  0.7146, -0.0528, -0.6747,  0.0447, -1.1310, -1.5243,\n",
      "        -1.0981,  0.5774,  1.2551, -0.6494,  0.5922,  0.6989,  0.1473, -0.0145,\n",
      "        -0.0366, -0.5596,  0.7257, -0.8536,  0.8610, -0.7257,  0.2120,  0.9780,\n",
      "         0.7839,  0.2417, -0.3819, -0.2503, -0.1283, -0.8077, -0.4196,  0.2372,\n",
      "         0.2957,  0.0673, -0.7731,  0.6046,  0.0396, -0.4549, -0.6280, -0.5806,\n",
      "        -0.2288, -0.2866, -0.5002,  0.0092, -0.5545, -0.9151, -0.9261,  0.4541,\n",
      "        -0.6398, -0.5445,  0.8034,  0.5008])\n",
      "Token: 3 is\n",
      "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
      "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
      "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
      "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
      "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
      "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
      "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
      "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
      "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
      "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
      "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
      "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
      "        -0.0442, -1.2969,  0.7622,  0.4635])\n",
      "Token: 4 my\n",
      "tensor([ 0.0803, -0.1086,  0.7207, -0.4514, -0.7496,  0.6378, -0.2571,  0.4161,\n",
      "        -0.0545,  0.3556,  0.3586,  0.5400,  0.4912,  0.2571, -0.2147, -0.4284,\n",
      "        -0.4232,  0.3872, -0.3569,  0.4012, -0.1985,  0.4345, -0.3648,  0.0717,\n",
      "         0.5332,  0.8456, -0.6754, -1.2527,  0.8376, -0.1593,  0.3780,  0.9454,\n",
      "         0.8307,  0.1943, -0.5845,  0.5828, -0.6256,  0.4904,  0.4327, -0.5425,\n",
      "         0.1045, -0.1626,  0.9900, -0.7422, -0.5978,  0.1019, -0.3357, -0.3909,\n",
      "         0.1513, -1.3533, -0.1126,  0.1435,  0.0381,  1.1167, -0.2308, -2.6394,\n",
      "         0.6685,  0.4845,  1.8796,  0.0803,  0.7373,  1.8058, -0.5193,  0.0041,\n",
      "         0.7699,  0.3688,  0.8114,  0.1694, -0.1192, -0.2650,  0.2269,  0.7694,\n",
      "         0.8520, -0.9777,  0.2318,  0.8814, -0.2709, -0.3991, -0.5719,  0.0756,\n",
      "         0.1809,  0.5904, -0.1343, -0.1206, -1.8157, -0.3550, -0.3172, -0.2704,\n",
      "        -0.6723, -0.0410, -0.4433,  0.3565,  1.0247,  0.4969, -0.5170, -0.4928,\n",
      "        -0.3340, -0.3484,  0.3147,  1.0087])\n",
      "Token: 5 favourite\n",
      "tensor([-0.1940,  0.3541,  0.2822,  0.1724,  0.2704,  0.1396,  0.1591, -0.7720,\n",
      "        -0.3762,  0.3975, -0.1416,  0.4423, -0.3516, -0.5530, -0.4717, -0.6723,\n",
      "         0.5679, -0.4082,  0.5990,  0.4092,  0.2158,  0.0971,  0.2438,  0.0473,\n",
      "         0.3074, -0.3747,  0.5012, -0.0125,  0.5104,  0.0588, -0.6519, -0.6154,\n",
      "         0.8037,  0.3766,  0.4369,  0.5948, -1.3332,  0.3028, -0.4533, -0.4701,\n",
      "         0.3375,  0.4101,  0.7957, -0.5891,  0.8702, -0.5519, -0.6112, -0.3940,\n",
      "         0.0656, -0.7240, -0.0208, -0.3677,  0.6728,  0.8627,  0.4074, -1.7477,\n",
      "        -0.4480,  1.0907, -0.1935, -0.5389,  0.1330,  0.1120,  0.5552,  0.8870,\n",
      "         0.9826, -0.0551, -0.1993,  0.0732,  0.0521, -0.5622, -0.7097,  0.0709,\n",
      "         0.1440,  0.0170, -0.8081,  0.3981, -0.0875, -0.2512,  0.5771, -0.1972,\n",
      "         0.1540, -0.1549, -0.0063, -0.0246, -0.4299, -1.1216, -0.9036,  0.5811,\n",
      "         0.0447,  0.0916, -0.8148,  0.4499,  0.5824,  0.4512, -0.7870, -0.1836,\n",
      "        -0.7215, -0.2009,  0.2092,  0.4484])\n"
     ]
    }
   ],
   "source": [
    "# sample sentence\n",
    "sentence = Sentence('Red wine is my favourite')\n",
    "\n",
    "# embed a sentence using glove.\n",
    "#glove_embedding.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextual string embeddings are powerful embeddings that capture latent syntactic-semantic information that goes beyond standard word embeddings.\n",
    "\n",
    "Key differences are: \n",
    "\n",
    "1. they are trained without any explicit notion of words and thus fundamentally model words as sequences of characters\n",
    "2. they are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Red wine is my favourite\"   [− Tokens: 5]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('Red wine is my favourite')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 Red\n",
      "tensor([-0.0002,  0.0018, -0.0321,  ...,  0.0012,  0.0179,  0.0066])\n",
      "Token: 2 wine\n",
      "tensor([-0.0008,  0.0027,  0.0160,  ..., -0.0028, -0.0090,  0.0397])\n",
      "Token: 3 is\n",
      "tensor([ 0.0008, -0.0015,  0.0603,  ..., -0.0050,  0.0121,  0.0107])\n",
      "Token: 4 my\n",
      "tensor([ 8.9246e-05,  8.9543e-05,  2.1088e-02,  ..., -6.4441e-04,\n",
      "         4.2823e-02,  1.8494e-03])\n",
      "Token: 5 favourite\n",
      "tensor([-9.1581e-04, -4.5748e-05,  1.9024e-02,  ..., -3.2326e-04,\n",
      "        -1.3051e-04,  2.0492e-02])\n"
     ]
    }
   ],
   "source": [
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following word embeddings are currently supported: \n",
    "\n",
    "| Class | Type | Paper | \n",
    "| ------------- | -------------  | -------------  | \n",
    "| [`BytePairEmbeddings`](/resources/docs/embeddings/BYTE_PAIR_EMBEDDINGS.md) | Subword-level word embeddings | [Heinzerling and Strube (2018)](https://www.aclweb.org/anthology/L18-1473)  |\n",
    "| [`CharacterEmbeddings`](/resources/docs/embeddings/CHARACTER_EMBEDDINGS.md) | Task-trained character-level embeddings of words | [Lample et al. (2016)](https://www.aclweb.org/anthology/N16-1030) |\n",
    "| [`ELMoEmbeddings`](/resources/docs/embeddings/ELMO_EMBEDDINGS.md) | Contextualized word-level embeddings | [Peters et al. (2018)](https://aclweb.org/anthology/N18-1202)  |\n",
    "| [`FastTextEmbeddings`](/resources/docs/embeddings/FASTTEXT_EMBEDDINGS.md) | Word embeddings with subword features | [Bojanowski et al. (2017)](https://aclweb.org/anthology/Q17-1010)  |\n",
    "| [`FlairEmbeddings`](/resources/docs/embeddings/FLAIR_EMBEDDINGS.md) | Contextualized character-level embeddings | [Akbik et al. (2018)](https://www.aclweb.org/anthology/C18-1139/)  |\n",
    "| [`OneHotEmbeddings`](/resources/docs/embeddings/ONE_HOT_EMBEDDINGS.md) | Standard one-hot embeddings of text or tags | - |\n",
    "| [`PooledFlairEmbeddings`](/resources/docs/embeddings/FLAIR_EMBEDDINGS.md) | Pooled variant of `FlairEmbeddings` |  [Akbik et al. (2019)](https://www.aclweb.org/anthology/N19-1078/)  | \n",
    "| [`TransformerWordEmbeddings`](/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md) | Embeddings from pretrained [transformers](https://huggingface.co/transformers/pretrained_models.html) (BERT, XLM, GPT, RoBERTa, XLNet, DistilBERT etc.) | [Devlin et al. (2018)](https://www.aclweb.org/anthology/N19-1423/) [Radford et al. (2018)](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)  [Liu et al. (2019)](https://arxiv.org/abs/1907.11692) [Dai et al. (2019)](https://arxiv.org/abs/1901.02860) [Yang et al. (2019)](https://arxiv.org/abs/1906.08237) [Lample and Conneau (2019)](https://arxiv.org/abs/1901.07291) |  \n",
    "| [`WordEmbeddings`](/resources/docs/embeddings/CLASSIC_WORD_EMBEDDINGS.md) | Classic word embeddings |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario A: using annotated (prepared) datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/_24.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario B: using your own annotated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "George N B-PER\n",
    "Washington N I-PER\n",
    "went V O\n",
    "to P O\n",
    "Washington N B-LOC\n",
    "\n",
    "Sam N B-PER\n",
    "Houston N I-PER\n",
    "stayed V O\n",
    "home N O\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'pos', 2: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '/path/to/data/folder'\n",
    "\n",
    "# # init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "# corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "#                               train_file='train.txt',\n",
    "#                               test_file='test.txt',\n",
    "#                               dev_file='dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get back to Scenario A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-24 11:34:59,511 Reading data from /home/simone/.flair/datasets/ud_english\n",
      "2020-06-24 11:34:59,512 Train: /home/simone/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2020-06-24 11:34:59,512 Dev: /home/simone/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2020-06-24 11:34:59,513 Test: /home/simone/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n",
      "Corpus: 1254 train + 200 dev + 208 test sentences\n",
      "Dictionary with 53 tags: <unk>, O, PRP, RB, VBP, IN, VB, VBN, JJR, NNP, ., DT, JJ, NN, ,, VBD, NNS, CC, VBG, MD, EX, CD, PRP$, WP, POS, VBZ, TO, WRB, JJS, UH\n",
      "2020-06-24 11:35:11,812 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:11,813 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=53, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-24 11:35:11,813 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:11,814 Corpus: \"Corpus: 1254 train + 200 dev + 208 test sentences\"\n",
      "2020-06-24 11:35:11,814 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:11,815 Parameters:\n",
      "2020-06-24 11:35:11,815  - learning_rate: \"0.1\"\n",
      "2020-06-24 11:35:11,817  - mini_batch_size: \"32\"\n",
      "2020-06-24 11:35:11,817  - patience: \"3\"\n",
      "2020-06-24 11:35:11,818  - anneal_factor: \"0.5\"\n",
      "2020-06-24 11:35:11,818  - max_epochs: \"150\"\n",
      "2020-06-24 11:35:11,819  - shuffle: \"True\"\n",
      "2020-06-24 11:35:11,819  - train_with_dev: \"False\"\n",
      "2020-06-24 11:35:11,821  - batch_growth_annealing: \"False\"\n",
      "2020-06-24 11:35:11,821 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:11,822 Model training base path: \"resources/taggers/example-pos\"\n",
      "2020-06-24 11:35:11,822 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:11,823 Device: cpu\n",
      "2020-06-24 11:35:11,824 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:11,824 Embeddings storage mode: cpu\n",
      "2020-06-24 11:35:11,826 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-24 11:35:13,187 epoch 1 - iter 4/40 - loss 73.49939728 - samples/sec: 94.15\n",
      "2020-06-24 11:35:14,789 epoch 1 - iter 8/40 - loss 68.21634436 - samples/sec: 80.49\n",
      "2020-06-24 11:35:16,057 epoch 1 - iter 12/40 - loss 63.69611295 - samples/sec: 101.69\n",
      "2020-06-24 11:35:17,217 epoch 1 - iter 16/40 - loss 60.52280211 - samples/sec: 111.36\n",
      "2020-06-24 11:35:18,540 epoch 1 - iter 20/40 - loss 58.51271324 - samples/sec: 97.60\n",
      "2020-06-24 11:35:19,954 epoch 1 - iter 24/40 - loss 56.95888710 - samples/sec: 91.08\n",
      "2020-06-24 11:35:21,110 epoch 1 - iter 28/40 - loss 55.55687727 - samples/sec: 111.67\n",
    
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.834558093346574,\n",
       " 'dev_score_history': [0.26642501132759405,\n",
       "  0.4461538461538461,\n",
       "  0.539768864717879,\n",
       "  0.6363636363636364,\n",
       "  0.6601853945286005,\n",
       "  0.6957110609480812,\n",
       "  0.7068654019873533,\n",
       "  0.7168960072185879,\n",
       "  0.7465583389754006,\n",
       "  0.753780185059806,\n",
       "  0.7657555906934719,\n",
       "  0.778505305938135,\n",
       "  0.780388612742883,\n",
       "  0.7717317678934297,\n",
       "  0.7920523820275457,\n",
       "  0.7978314885927265,\n",
       "  0.7847300655071154,\n",
       "  0.8006314839873703,\n",
       "  0.8094808126410835,\n",
       "  0.8121896162528216,\n",
       "  0.8159855497855046,\n",
       "  0.8220415537488708,\n",
       "  0.8189616252821671,\n",
       "  0.8131917777275808],\n",
       " 'train_loss_history': [53.158365631103514,\n",
       "  40.7812376499176,\n",
       "  33.89535856246948,\n",
       "  28.774631690979003,\n",
       "  25.575098514556885,\n",
       "  23.40834789276123,\n",
       "  21.724063682556153,\n",
       "  20.738570284843444,\n",
       "  19.54983322620392,\n",
       "  19.030347990989686,\n",
       "  18.23484809398651,\n",
       "  17.77282521724701,\n",
       "  16.75617399215698,\n",
       "  16.35137629508972,\n",
       "  16.097274255752563,\n",
       "  15.75730516910553,\n",
       "  15.434643626213074,\n",
       "  15.073633074760437,\n",
       "  14.601285386085511,\n",
       "  14.17440025806427,\n",
       "  14.091671776771545,\n",
       "  13.515327858924866,\n",
       "  13.75264115333557,\n",
       "  13.277540969848634],\n",
       " 'dev_loss_history': [29.557079315185547,\n",
       "  22.730993270874023,\n",
       "  18.454727172851562,\n",
       "  14.629263877868652,\n",
       "  13.127612113952637,\n",
       "  11.939422607421875,\n",
       "  11.031184196472168,\n",
       "  10.523231506347656,\n",
       "  9.60346794128418,\n",
       "  9.251897811889648,\n",
       "  8.846505165100098,\n",
       "  8.3197021484375,\n",
       "  8.148077964782715,\n",
       "  8.169198036193848,\n",
       "  7.650144100189209,\n",
       "  7.284870147705078,\n",
       "  7.4856719970703125,\n",
       "  7.108133792877197,\n",
       "  6.840267658233643,\n",
       "  6.793857097625732,\n",
       "  6.490757465362549,\n",
       "  6.306644916534424,\n",
       "  6.401901721954346,\n",
       "  6.42360782623291]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import UD_ENGLISH\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = UD_ENGLISH().downsample(0.1)\n",
    "print(corpus)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'pos'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
